services:
  
  ollama:
    container_name: ollama
    build:
      context: ./ollama
    ports:
      - "11434:11434"
    networks:
      - ai-hacking-net
    volumes:
      - ./ollama/src:/root/.ollama  # Shared model storage

  kali:
    container_name: kali
    build:
      context: ./kali  # Build from the kali directory
    stdin_open: true
    tty: true
    ports:
      - "2222:22"
    networks:
      - ai-hacking-net
    privileged: true
    volumes:
      - kali-home:/root

  openwebui:
    container_name: openwebui
    build:
      context: ./openwebui   # This folder contains your main.py, templates/, static/ etc.
    depends_on:
      - ollama
      - kali
    networks:
      - ai-hacking-net
    ports:
      - "3000:8080"         # Access your OpenWebUI at http://localhost:3000
    volumes:
      - openwebui_data:/app/backend/data
    environment:
      - OLLAMA_API=http://ollama:11434
      - KALI_SSH_HOST=kali
      - KALI_SSH_PORT=22
      - KALI_SSH_USER=root
      - KALI_SSH_PASS=kali
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: always

volumes:
  kali-home:
  openwebui_data:

networks:
  ai-hacking-net:
    driver: bridge
